nohup: ignoring input
Dataset name: Taobao
The number of users: 48749
The number of items: 39493
The behavior ratings: [1548162, 193747, 211022]
The number of ratings: 1952931
Average actions of users: 40.06
Average actions of items: 49.45
The density of the dataset: 0.001014
The sparsity of the dataset: 99.898562%
already load adj matrix 0.5032174587249756
already load pre adj matrix
use the pre adjcency matrix
213
54
50
without pretraining.
W_gc_0
W_gc_1
W_gc_2
W_gc_3
W_rel_0
W_rel_1
W_rel_2
W_rel_3
Epoch 0 [240.1s]: train==[-52.83042=-123.89992 + 0.47521 + 42.23591 + 28.35838]
Epoch 1 [240.4s]: train==[-210.96438=-283.25411 + 0.65457 + 42.72785 + 28.90731]
Epoch 2 [241.0s]: train==[-232.50712=-303.24761 + 0.64525 + 41.87240 + 28.22285]
Epoch 3 [244.4s]: train==[-273.90357=-344.02570 + 0.69862 + 41.48015 + 27.94337]
Epoch 4 [260.1s + 78.4s]:, recall=[0.01493, 0.02365], precision=[0.00149, 0.00118], hit=[0.01493, 0.02365], ndcg=[0.00765, 0.00983]
Epoch 5 [237.6s]: train==[-352.63835=-422.14745 + 0.73880 + 41.07717 + 27.69313]
Epoch 6 [240.7s]: train==[-403.24094=-472.45376 + 0.70747 + 40.95195 + 27.55341]
Epoch 7 [298.1s]: train==[-445.86153=-514.91071 + 0.67270 + 40.87920 + 27.49728]
Epoch 8 [238.3s]: train==[-481.47327=-550.42066 + 0.65794 + 40.82973 + 27.45972]
Epoch 9 [239.5s + 80.4s]:, recall=[0.03506, 0.05362], precision=[0.00351, 0.00268], hit=[0.03506, 0.05362], ndcg=[0.01904, 0.02369]
Epoch 10 [240.6s]: train==[-538.47013=-607.28423 + 0.65341 + 40.76704 + 27.39366]
Epoch 11 [236.9s]: train==[-561.94398=-630.72306 + 0.66156 + 40.75012 + 27.36740]
Epoch 12 [238.1s]: train==[-583.26603=-652.01862 + 0.67339 + 40.74127 + 27.33793]
Epoch 13 [235.5s]: train==[-602.53372=-671.27362 + 0.68673 + 40.73903 + 27.31414]
Epoch 14 [242.6s + 81.7s]:, recall=[0.04773, 0.07135], precision=[0.00477, 0.00357], hit=[0.04773, 0.07135], ndcg=[0.02605, 0.03199]
Epoch 15 [239.9s]: train==[-635.03942=-703.77340 + 0.71442 + 40.73969 + 27.27987]
Epoch 16 [241.7s]: train==[-647.74966=-716.49490 + 0.72857 + 40.74520 + 27.27147]
Epoch 17 [237.0s]: train==[-658.31921=-727.07790 + 0.74286 + 40.74961 + 27.26621]
Epoch 18 [249.5s]: train==[-667.07760=-735.84715 + 0.75730 + 40.75120 + 27.26104]
Epoch 19 [235.2s + 79.6s]:, recall=[0.05192, 0.07723], precision=[0.00519, 0.00386], hit=[0.05192, 0.07723], ndcg=[0.02825, 0.03459]
Epoch 20 [235.5s]: train==[-680.86804=-749.66711 + 0.78630 + 40.75646 + 27.25630]
Epoch 21 [237.8s]: train==[-685.87425=-754.68301 + 0.80174 + 40.75586 + 27.25116]
Epoch 22 [234.8s]: train==[-690.87439=-759.69742 + 0.81669 + 40.75767 + 27.24866]
Epoch 23 [265.6s]: train==[-694.90333=-763.74385 + 0.83192 + 40.75932 + 27.24927]
Epoch 24 [252.6s + 77.4s]:, recall=[0.05128, 0.07811], precision=[0.00513, 0.00391], hit=[0.05128, 0.07811], ndcg=[0.02810, 0.03483]
Epoch 25 [236.5s]: train==[-701.67178=-770.53951 + 0.86247 + 40.75615 + 27.24910]
Epoch 26 [237.7s]: train==[-704.35593=-773.24407 + 0.87883 + 40.75926 + 27.25006]
Epoch 27 [235.6s]: train==[-707.45259=-776.35541 + 0.89550 + 40.75767 + 27.24965]
Epoch 28 [236.1s]: train==[-710.02160=-778.93439 + 0.91262 + 40.75360 + 27.24657]
Epoch 29 [239.0s + 85.6s]:, recall=[0.05071, 0.07740], precision=[0.00507, 0.00387], hit=[0.05071, 0.07740], ndcg=[0.02767, 0.03439]
